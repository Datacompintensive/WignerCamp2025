{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "open-colab",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Datacompintensive/WignerCamp2025/blob/master/ALT/presentation_calculation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "# Introduction to ALT – A Simple Numerical Demonstration\n",
    "\n",
    "This notebook introduces the **Adaptive Law-based Transformation (ALT)** with a minimal numerical example. ALT is a lightweight, interpretable, and effective method for **time series classification**. It extracts characteristic patterns—called *shapelets*—from the training data and uses them to transform new data into a feature space where classes are more easily separable.\n",
    "\n",
    "We demonstrate each step using a synthetic example with only a few elements, allowing full transparency into how ALT works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "autoreload",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-input",
   "metadata": {},
   "source": [
    "## Step 1: Define a minimal training and test set\n",
    "We generate synthetic time series using simple **linear recursion rules**:\n",
    "- Class `a` is generated using the Fibonacci rule: $x_n = x_{n-1} + x_{n-2}$. ($w=[1, 1]$).\n",
    "- Class `b` uses a different rule: $x_n = 2x_{n-2} + x_{n-1}$. ($w=[2, 1]$).\n",
    "- The test sample also follows the Fibonacci rule but starts from different initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generate-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train instance for class 'a': tensor([1., 1., 2., 3., 5.])\n",
      "Train instance for class 'b': tensor([ 2.,  1.,  5.,  7., 17.])\n",
      "Test instance 'x': tensor([ 2.,  3.,  5.,  8., 13.]) belonging to an unknown class.\n"
     ]
    }
   ],
   "source": [
    "a = generate_recursive_array([1, 1], [1, 1], 5)\n",
    "print(f\"Train instance for class 'a': {a}\")\n",
    "b = generate_recursive_array([2, 1], [2, 1], 5)\n",
    "print(f\"Train instance for class 'b': {b}\")\n",
    "x = generate_recursive_array([1, 1], [2, 3], 5)\n",
    "print(f\"Test instance 'x': {x} belonging to an unknown class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-laws",
   "metadata": {},
   "source": [
    "## Step 2: Extract Laws from Training Data\n",
    "We extract **shapelet vectors** (or 'laws') from each training instance. Each law is a direction in space that characterizes how values change locally.\n",
    "\n",
    "We use parameters $R=3$, $L=2$, $K=1$, meaning:\n",
    "- $R=3$: the length of subsequences considered.\n",
    "- $L=2$: the size of the matrix constructed from those sequences.\n",
    "- $K=1$: the shift between consecutive windows.\n",
    "\n",
    "The shapelet vectors are obtained by computing the eigenvector of a symmetric matrix (constructed via time-delay embedding) corresponding to the **smallest eigenvalue**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extract-laws-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laws for class 'a':\n",
      "tensor([[-0.8507, -0.8507, -0.8507],\n",
      "        [ 0.5257,  0.5257,  0.5257]])\n",
      "Laws for class 'b':\n",
      "tensor([[-0.9571, -0.8702, -0.9085],\n",
      "        [ 0.2898,  0.4927,  0.4179]])\n"
     ]
    }
   ],
   "source": [
    "laws_a = extract_symmetric_laws(a)\n",
    "laws_b = extract_symmetric_laws(b)\n",
    "print(f\"Laws for class 'a':\\n{laws_a}\")\n",
    "print(f\"Laws for class 'b':\\n{laws_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embed-test",
   "metadata": {},
   "source": [
    "## Step 3: Embed the Test Instance\n",
    "We now embed the test instance into 2D vectors (pairs of values) that will be multiplied by the laws. This step constructs an input matrix $E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "embed-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedded test instance: \n",
      "tensor([[ 2.,  3.],\n",
      "        [ 3.,  5.],\n",
      "        [ 5.,  8.],\n",
      "        [ 8., 13.]])\n"
     ]
    }
   ],
   "source": [
    "embedded = embed_as_pairs(x)\n",
    "print(f\"The embedded test instance: \\n{embedded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiply-laws",
   "metadata": {},
   "source": [
    "## Step 4: Apply Laws (Matrix Multiplication)\n",
    "We apply the transformation by multiplying the embedded matrix with the laws of each class. The goal is that the *correct laws* will make the result close to zero vectors, while *incorrect laws* won’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multiply-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplying with laws from class 'a' gives:\n",
      "tensor([[-0.1241, -0.1241, -0.1241],\n",
      "        [ 0.0767,  0.0767,  0.0767],\n",
      "        [-0.0474, -0.0474, -0.0474],\n",
      "        [ 0.0293,  0.0293,  0.0293]])\n",
      "Multiplying with laws from class 'b' gives:\n",
      "tensor([[-1.0448, -0.2623, -0.5635],\n",
      "        [-1.4224, -0.1471, -0.6363],\n",
      "        [-2.4672, -0.4094, -1.1997],\n",
      "        [-3.8895, -0.5565, -1.8360]])\n"
     ]
    }
   ],
   "source": [
    "F_a = embedded @ laws_a\n",
    "F_b = embedded @ laws_b\n",
    "print(f\"Multiplying with laws from class 'a' gives:\\n{F_a}\")\n",
    "print(f\"Multiplying with laws from class 'b' gives:\\n{F_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-step",
   "metadata": {},
   "source": [
    "## Step 5: Feature Extraction from Transformed Matrix\n",
    "From the result of the transformation, we compute a simple **statistical feature**: the average of the squared values (mean of $F^2$). Lower values indicate better alignment with the laws of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stats-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 'a': mean_all: 0.00609796354547143\n",
      "For class 'b': mean_all: 2.5358715057373047\n",
      "\n",
      "Based on the method the unknown instance belongs to class: 'a'.\n"
     ]
    }
   ],
   "source": [
    "res_a = torch.mean(F_a**2)\n",
    "res_b = torch.mean(F_b**2)\n",
    "print(f\"For class 'a': mean_all: {res_a}\")\n",
    "print(f\"For class 'b': mean_all: {res_b}\")\n",
    "print(f\"\\nBased on the method the unknown instance belongs to class: '{'a' if res_a < res_b else 'b'}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this minimal example, ALT successfully classified the test sequence. The method:\n",
    "- Extracted characteristic patterns (laws) from the training classes.\n",
    "- Transformed the new sequence into a comparison-friendly space.\n",
    "- Used simple statistics to determine which class's laws best describe the new data.\n",
    "\n",
    "This illustrates how **ALT builds an interpretable and efficient classification pipeline**, leveraging linear algebra and time-delay embeddings.\n",
    "\n",
    "For more advanced applications, ALT supports multiple channels, longer sequences, and sophisticated feature extraction techniques like percentiles and higher moments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompPhys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
